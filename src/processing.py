# src/processing.py

import pandas as pd
import numpy as np
import re
from datetime import datetime
import os

# --- Fun√ß√µes de Limpeza e Convers√£o ---

def limpar_texto(texto: str) -> str:
    """
    Limpa strings removendo espa√ßos extras e quebras de linha.

    Args:
        texto (str): O texto a ser limpo.

    Returns:
        str: O texto limpo.
    """
    if isinstance(texto, str):
        # Substitui m√∫ltiplos espa√ßos e quebras de linha por um √∫nico espa√ßo e remove espa√ßos no in√≠cio/fim
        texto = re.sub(r'\s+', ' ', texto).strip()
    return texto

def limpar_valor(valor: str) -> float:
    """
    Limpa e converte strings de valores monet√°rios para float.
    Lida com "R$", pontos de milhar, v√≠rgulas decimais e sinais negativos.

    Args:
        valor (str): O valor monet√°rio como string.

    Returns:
        float: O valor num√©rico ou NaN se a convers√£o falhar.
    """
    if isinstance(valor, str):
        valor = valor.replace("R$", "").replace(".", "").replace(",", ".").strip()
        # Corrige casos como "- 75.88" para "-75.88"
        valor = re.sub(r"^-?\s+", "-", valor)
    try:
        return float(valor)
    except (ValueError, TypeError):
        return np.nan

def eh_ajuste_negativo(observacao: str, valor: float) -> bool:
    """
    Verifica se uma despesa √© um ajuste negativo baseado na observa√ß√£o ou valor.

    Args:
        observacao (str): A string de observa√ß√£o da despesa.
        valor (float): O valor num√©rico da despesa.

    Returns:
        bool: True se for um ajuste negativo, False caso contr√°rio.
    """
    # Converter observa√ß√£o para min√∫sculas para padronizar a busca
    if isinstance(observacao, str):
        observacao_lower = observacao.lower()
        palavras_chave = ['anulacao', 'reforco', 'cancelamento', 'estorno']
        for palavra in palavras_chave:
            if palavra in observacao_lower:
                return True
    
    # Considerar valores negativos expl√≠citos
    if isinstance(valor, (int, float)) and valor < 0:
        return True
        
    return False

# --- Fun√ß√£o Principal de Processamento ---

def processar_dados_financeiros(ano: int, tipo_dado: str, input_base_path: str = 'data', output_base_path: str = 'data'):
    """
    Fun√ß√£o principal para processar dados financeiros (pagamentos, empenhos, liquida√ß√µes).
    Realiza limpeza, convers√£o de tipos, detec√ß√£o de duplicatas e ajustes negativos,
    e exporta os dados tratados para a camada trusted.

    Args:
        ano (int): O ano dos dados a serem processados.
        tipo_dado (str): O tipo de dado (ex: 'pagamentos', 'empenhos', 'liquidacoes').
        input_base_path (str): Caminho base para os dados de entrada (raw).
        output_base_path (str): Caminho base para os dados de sa√≠da (trusted).

    Returns:
        tuple: Uma tupla contendo (DataFrame completo, DataFrame normal, DataFrame de ajustes negativos).
    """
    # Constru√ß√£o dos caminhos de arquivo de forma flex√≠vel
    raw_file_name = f"{tipo_dado}_{ano}.csv"
    caminho_arquivo_raw = os.path.join(input_base_path,'raw', str(ano),  raw_file_name)
    
    trusted_output_dir = os.path.join(output_base_path,  'trusted', str(ano), tipo_dado)
    os.makedirs(trusted_output_dir, exist_ok=True)

    print(f"üîç Lendo arquivo: {caminho_arquivo_raw}")
    
    try:
        df = pd.read_csv(caminho_arquivo_raw, sep=',', encoding='utf-8')
        print(f"‚úÖ {len(df)} registros carregados de '{raw_file_name}'.")
    except FileNotFoundError:
        print(f"‚ùå Erro: Arquivo n√£o encontrado em '{caminho_arquivo_raw}'.")
        return None, None, None
    except Exception as e:
        print(f"‚ùå Erro ao ler o arquivo: {e}")
        return None, None, None
    
    # 1. Limpeza inicial de texto
    # Seleciona colunas de texto (object) e aplica a limpeza
    col_texto = df.select_dtypes(include='object').columns
    for col in col_texto:
        df[col] = df[col].astype(str).apply(limpar_texto)
    print("üßπ Limpeza de texto aplicada.")

    # 2. Convers√£o de colunas de data
    # Assumimos que a coluna de data se chama 'data'. Ajuste se for diferente.
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y', errors='coerce')
        print("üìÖ Coluna 'data' convertida para datetime.")
    else:
        print("‚ö†Ô∏è Coluna 'data' n√£o encontrada. Pulando convers√£o de data.")
    
    # 3. Convers√£o da coluna 'valor' para float
    if 'valor' in df.columns:
        df['valor'] = df['valor'].apply(limpar_valor)
        print("üí≤ Coluna 'valor' convertida para float.")
    else:
        print("‚ö†Ô∏è Coluna 'valor' n√£o encontrada. Pulando convers√£o de valor.")

    # 4. Criar colunas temporais (se a coluna 'data' existir e for datetime)
    if 'data' in df.columns and pd.api.types.is_datetime64_any_dtype(df['data']):
        df['dia'] = df['data'].dt.day
        df['mes'] = df['data'].dt.month
        df['ano'] = df['data'].dt.year
        df['mes_ano'] = df['data'].dt.strftime('%m-%Y')
        print("üìä Colunas temporais (dia, m√™s, ano, m√™s_ano) criadas.")
    else:
        print("‚ö†Ô∏è N√£o foi poss√≠vel criar colunas temporais (coluna 'data' ausente ou inv√°lida).")

    # 5. Identificar e remover duplicatas
    # Subconjunto de colunas para identificar duplicatas
    # Ajuste 'documento' se o nome da coluna for diferente para Empenhos/Liquida√ß√µes
    subset_duplicatas = ['documento', 'valor'] 
    if 'documento' not in df.columns: # Caso o nome da coluna seja 'numero_documento' ou similar
         print("‚ö†Ô∏è Coluna 'documento' n√£o encontrada. Usando ['valor', 'data'] para duplicatas.")
         subset_duplicatas = ['valor', 'data'] # Fallback mais seguro
    
    duplicados_df = pd.DataFrame() # DataFrame vazio para armazenar duplicatas
    
    # O `keep=False` marca todas as ocorr√™ncias de duplicatas
    duplicados_marcados = df[df.duplicated(subset=subset_duplicatas, keep=False)]
    
    if not duplicados_marcados.empty:
        print(f"‚ö†Ô∏è Encontrados {len(duplicados_marcados)} registros duplicados com base em {subset_duplicatas}.")
        duplicados_df = duplicados_marcados.copy() # Copia os registros duplicados ANTES de remover
        
        # Remove as duplicatas do DataFrame principal, mantendo a primeira ocorr√™ncia
        df = df.drop_duplicates(subset=subset_duplicatas, keep='first').copy()
        
        print("‚úÖ Duplicatas removidas do DataFrame principal.")
    else:
        print("‚úÖ Nenhuma duplicata encontrada.")

    # 6. Detectar ajustes negativos
    # Assumimos que a coluna de observa√ß√£o √© 'observacao'. Ajuste se for diferente.
    if 'observacao' in df.columns:
        df['observacao_lower'] = df['observacao'].str.lower() # Cria uma nova coluna tempor√°ria para evitar modificar a original se n√£o for desejado
        df['eh_ajuste_negativo'] = df.apply(lambda row: eh_ajuste_negativo(row['observacao_lower'], row['valor']), axis=1)
        df = df.drop(columns=['observacao_lower']) # Remove a coluna tempor√°ria
        print("üîé Ajustes negativos identificados.")
    else:
        print("‚ö†Ô∏è Coluna 'observacao' n√£o encontrada. Pulando detec√ß√£o de ajustes negativos.")
        df['eh_ajuste_negativo'] = False # Define como False por padr√£o se n√£o houver observa√ß√£o

    # 7. Separar DataFrames
    registros_normais = df[df['eh_ajuste_negativo'] == False].copy()
    ajustes_negativos = df[df['eh_ajuste_negativo'] == True].copy()
    
    print(f"üìÅ Registros normais de {tipo_dado}: {len(registros_normais)} | Ajustes negativos de {tipo_dado}: {len(ajustes_negativos)}")

    # 8. Exportar para CSV e Excel
    # Salvando em CSV
    registros_normais.to_csv(os.path.join(trusted_output_dir, f'{tipo_dado}_normais.csv'), index=False, encoding='utf-8-sig')
    ajustes_negativos.to_csv(os.path.join(trusted_output_dir, f'{tipo_dado}_ajustes_negativos.csv'), index=False, encoding='utf-8-sig')
    if not duplicados_df.empty: # Exporta duplicatas apenas se existirem
        duplicados_df.to_csv(os.path.join(trusted_output_dir, f'{tipo_dado}_duplicatas_detectadas.csv'), index=False, encoding='utf-8-sig')


    # Salvando em Excel com m√∫ltiplas abas
    output_excel_file = os.path.join(trusted_output_dir, f'{tipo_dado}_{ano}_processadas.xlsx')
    with pd.ExcelWriter(output_excel_file, engine='xlsxwriter') as writer:
        df.to_excel(writer, sheet_name='Todos_Registros', index=False, float_format="%.2f")
        registros_normais.to_excel(writer, sheet_name=f'{tipo_dado.capitalize()}_Normais', index=False, float_format="%.2f")
        ajustes_negativos.to_excel(writer, sheet_name='Ajustes_Negativos', index=False, float_format="%.2f")
        if not duplicados_df.empty:
            duplicados_df.to_excel(writer, sheet_name='Duplicatas', index=False, float_format="%.2f")

    print(f"‚úÖ Arquivos tratados de {tipo_dado} salvos com sucesso em: {trusted_output_dir}")

    return df, registros_normais, ajustes_negativos